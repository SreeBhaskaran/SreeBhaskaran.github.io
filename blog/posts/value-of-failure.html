<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>The Value of Failure | Sreekumar R. Bhaskaran</title>
  <meta name="description" content="The Value of Failure: What Wordle Teaches Us About Experimentation" />

  <!-- Inter font (matches your site) -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">

  <!-- Font Awesome (icons) -->
  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">

  <!-- Your main site CSS -->
  <link rel="stylesheet" href="../../assets/style.css" />

  <!-- Post-specific styling -->
  <style>
    .post { max-width: 860px; margin: 0 auto; padding: 26px 0 50px; }
    .post-header h1 { margin: 0 0 10px; font-size: 34px; line-height: 1.15; }
    .post-meta { margin: 0 0 18px; color: var(--muted); font-size: 14px; display:flex; flex-wrap:wrap; gap:10px; align-items:center; }
    .tag { display:inline-flex; padding: 4px 10px; border-radius: 999px; border: 1px solid var(--border); background: rgba(53,76,161,.06); color: var(--text); font-size: 12px; }
    .post-section { padding: 14px 0; }
    .post-section h2 { margin: 22px 0 10px; font-size: 22px; }
    .callout { border: 1px solid var(--border); background: rgba(204,0,53,.06); border-radius: 14px; padding: 14px; margin: 18px 0; }
    .pullquote { margin: 18px 0; padding: 14px 16px; border-left: 4px solid var(--smu-red); background: rgba(15,23,42,.03); border-radius: 12px; font-size: 18px; line-height: 1.4; }
    .post-img { margin: 18px 0; border-radius: 14px; border: 1px solid var(--border); overflow:hidden; background:#fff; }
    .post-img img { display:block; width:100%; height:auto; }
    .caption { font-size: 13px; color: var(--muted); padding: 10px 12px; border-top: 1px solid var(--border); background: rgba(15,23,42,.02); }
    .refs { margin-top: 28px; padding-top: 18px; border-top: 1px solid var(--border); }
    .refs ul { margin: 8px 0 0; padding-left: 18px; }
  </style>
</head>

<body>

  <!-- Top-right nav only -->
  <header class="topbar">
    <div class="wrap nav" style="justify-content:flex-end;">
      <a href="../../index.html" aria-label="Home">Home</a>
      <a href="../../blog.html">Blog</a>
    </div>
  </header>

  <main class="wrap">
    <article class="post">

      <header class="post-header">
        <h1>The Value of Failure: What Wordle Teaches Us About Experimentation</h1>
        <p class="post-meta">
          <span class="tag">Experimentation</span>
          <span class="tag">AI</span>
          <span class="tag">Innovation</span>
          <span class="tag">Decision Making</span>
          <span>·</span>
          <time datetime="2025-12-25">December 25, 2025</time>
        </p>
      </header>

      <section class="post-section">
        <p>
          Across industries, firms are running more experiments than ever—yet many are less sure what they are learning.
          With consumers becoming more discerning and competitive pressure to find what works, firms increasingly rely on pilots,
          A/B tests, and proof-of-concepts before committing meaningful resources. This is especially true in digital products,
          innovation, and AI—domains where the rules are still emerging and early feedback can be difficult to interpret.
          The logic is straightforward: experiment early, learn cheaply, and avoid costly mistakes later.
          Yet, as a recent <em>Wall Street Journal</em> article observed, many companies that “had fun experimenting” are now under pressure
          to demonstrate real returns from those efforts. As WSJ notes,
          “Business technology leaders are winding down two years of fast-paced artificial intelligence experiments… and putting their AI dollars
          toward proven projects focused on return on investment.” The implicit promise of experimentation—that it reliably produces learning—has
          started to feel less certain.
        </p>

        <p>
          Large investments in AI pilots haven’t resolved the problem. A <em>Forbes</em> article notes that despite billions spent on enterprise AI,
          most organizations struggle to move beyond the pilot stage, and even those that do often find meaningful returns elusive.
          Another industry report reinforces this: unclear objectives, insufficient data readiness, a lack of in-house expertise,
          and misguided pressure to greenlight proofs of concept are sinking many AI initiatives before they reach production.
        </p>

        <div class="callout">
          <strong>Key takeaway:</strong> Many firms aren’t struggling because they lack experimentation—they’re struggling because they lack interpretability and scalability.
        </div>
      </section>

      <!-- IMAGE 1 -->
      <div class="post-img">
        <img src="../assets/img/wordle.png" alt="Learning from Wordle illustration">
        <div class="caption">Failure can be the most informative feedback—if the guess was designed to learn.</div>
      </div>

      <section class="post-section">
        <h2>Where the Problem Lies: Method and Intent</h2>

        <p>
          So where does the problem lie? It lies in both the method and the intent behind experimentation. Executives increasingly report pilots that
          generate mixed or contradictory signals, experiments that fail to scale, and early results that are difficult to interpret with confidence.
          In many cases, the challenge is not a lack of data—it is the nature of the information experiments generate. Early feedback is often noisy,
          incomplete, and easy to misread. And without clarity on the purpose of the experiment, even good data can lead to ambiguous conclusions.
        </p>

        <p>
          The deployment of AI to automate processes and accelerate testing does not automatically solve these issues. If anything, it can make them worse:
          broad, general-purpose AI models can introduce additional noise into the experimentation process, especially when the underlying measurement systems
          are already imperfect. Scaling isn’t about running more pilots. It’s about moving a smaller number of well-governed models into production with confidence.
        </p>
      </section>

      <!-- IMAGE 2 -->
      <div class="post-img">
        <img src="../assets/img/signal-noise.png" alt="Signal vs noise illustration">
        <div class="caption">Observed outcomes mix signal + noise — clarity requires smart design, not volume.</div>
      </div>

      <section class="post-section">
        <h2>Experimentation in the Age of AI</h2>

        <p>
          The business landscape has accelerated. Consumer needs shift faster. Competitive cycles are shorter. AI has rewritten the rules of product development—through
          wireframes, simulations, and rapid prototyping tools that allow teams to test more ideas than ever before.
        </p>

        <p>
          But the organizations that win won’t be those that simply test more. They will be those that test with intention—designing experiments that generate learning,
          recognizing when noise overwhelms signal, and building foundations strong enough to scale what works.
          Experimentation is no longer just a tool for discovery. In the age of AI, it is a strategic capability.
        </p>
      </section>

      <!-- IMAGE 3 -->
      <div class="post-img">
        <img src="../assets/img/funnel.png" alt="Experiment funnel illustration">
        <div class="caption">Many pilots. Few scale — scaling requires governance and strong foundations.</div>
      </div>

      <section class="post-section">
        <h2>Noisy Experimentation and Incentives</h2>

        <p>
          This is precisely what we study in our research on noisy experimentation
          (<a href="https://pubsonline.informs.org/doi/abs/10.1287/msom.2024.1133" target="_blank" rel="noopener noreferrer">M&amp;SOM paper</a>).
          The core idea is that experimentation under significant noise requires a fundamentally different approach.
        </p>

        <p>
          There is a second reason experimentation can mislead: experiments don’t happen in a vacuum.
          As my co-author Sanjiv Erat and his colleagues (Ping-Chieh Huang and Zhe Zhang) have shown, experiments can change behavior by shaping incentives
          (<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4976827" target="_blank" rel="noopener noreferrer">SSRN paper</a>).
          When people know they are being evaluated, they optimize for winning the evaluation, not for producing the best underlying outcome.
        </p>
      </section>

      <!-- IMAGE 4 -->
      <div class="post-img">
        <img src="../assets/img/incentives.png" alt="Incentives in competitions illustration">
        <div class="caption">Incentives can distort what experiments reveal — and firms may select the “best” from a biased set.</div>
      </div>

      <footer class="refs">
        <h3>References</h3>
        <ul>
          <li><a href="https://pubsonline.informs.org/doi/abs/10.1287/msom.2024.1133" target="_blank" rel="noopener noreferrer">Optimal Prototyping with Noisy Measurements (M&amp;SOM)</a></li>
          <li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4976827" target="_blank" rel="noopener noreferrer">Data Science Contests and the Perils of Intermediate Split Ratios (SSRN)</a></li>
        </ul>
      </footer>

    </article>
  </main>
</body>
</html>
